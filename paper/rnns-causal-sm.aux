\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\zref@newlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\@writefile{toc}{\contentsline {section}{\numberline {1}RNNs architecture}{1}{section.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Encoder-decoder networks architecture. Dropout is applied to the visible input sequences, which are then fed to a two-layer bidirectional LSTM encoder. The encoder encodes the input sequences into a single vector that contains information about the entire sequence. The output of the encoder is repeated $t$ times and fed to the single-layer GRU decoder, which translates the encoded sequence into the predicted sequence. Finally, a dense layer is applied to the decoder output to generate predictions. \relax }}{1}{figure.caption.2}}
\newlabel{encoder-decoder}{{1}{1}{Encoder-decoder networks architecture. Dropout is applied to the visible input sequences, which are then fed to a two-layer bidirectional LSTM encoder. The encoder encodes the input sequences into a single vector that contains information about the entire sequence. The output of the encoder is repeated $t$ times and fed to the single-layer GRU decoder, which translates the encoded sequence into the predicted sequence. Finally, a dense layer is applied to the decoder output to generate predictions. \relax }{figure.caption.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Recurrent VAE architecture. First, an LSTM encoder turns the input samples into two parameters in a latent space. Latent space points are randomly sampled from the latent distribution that is assumed to generate the data. The sampling output is repeated $t$ times and fed to the decoder LSTM, which maps the latent space points back to the original input data. \relax }}{2}{figure.caption.3}}
\newlabel{vae}{{2}{2}{Recurrent VAE architecture. First, an LSTM encoder turns the input samples into two parameters in a latent space. Latent space points are randomly sampled from the latent distribution that is assumed to generate the data. The sampling output is repeated $t$ times and fed to the decoder LSTM, which maps the latent space points back to the original input data. \relax }{figure.caption.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2}RNNs training history: SCM datasets}{3}{section.2}}
\newlabel{encoder-decoder-loss-basque-treated}{{3a}{3}{Basque Country (treated) \relax }{figure.caption.4}{}}
\newlabel{sub@encoder-decoder-loss-basque-treated}{{a}{3}{Basque Country (treated) \relax }{figure.caption.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Evolution of encoder-decoder networks training and validation loss in terms of MSPE. \relax }}{3}{figure.caption.4}}
\newlabel{encoder-decoder-loss-scm}{{3}{3}{Evolution of encoder-decoder networks training and validation loss in terms of MSPE. \relax }{figure.caption.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Evolution of baseline LSTM training and validation loss in terms of MSPE. \relax }}{4}{figure.caption.5}}
\newlabel{lstm-loss-scm}{{4}{4}{Evolution of baseline LSTM training and validation loss in terms of MSPE. \relax }{figure.caption.5}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Evolution of VAE training and validation loss in terms of MSPE. \relax }}{5}{figure.caption.6}}
\newlabel{vae-loss-scm}{{5}{5}{Evolution of VAE training and validation loss in terms of MSPE. \relax }{figure.caption.6}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Estimates on Basque Country data}{6}{section.3}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Observed and counterfactual predicted outcomes for treated unit in Basque Country dataset.\relax }}{6}{figure.caption.7}}
\newlabel{basque-plot}{{6}{6}{Observed and counterfactual predicted outcomes for treated unit in Basque Country dataset.\relax }{figure.caption.7}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Time-series of post-period treatment effects in Basque Country dataset. Darker line represents the effect on the actual treated unit and each lighter line represents the effects on control units. Shaded regions represent 95\% randomization confidence intervals. \relax }}{7}{figure.caption.8}}
\newlabel{basque-plot-effects}{{7}{7}{Time-series of post-period treatment effects in Basque Country dataset. Darker line represents the effect on the actual treated unit and each lighter line represents the effects on control units. Shaded regions represent 95\% randomization confidence intervals. \relax }{figure.caption.8}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces Per-period randomization $p$-values corresponding to treatment effects on treated and control units in Basque Country dataset. \relax }}{8}{figure.caption.9}}
\newlabel{basque-plot-pvalues}{{8}{8}{Per-period randomization $p$-values corresponding to treatment effects on treated and control units in Basque Country dataset. \relax }{figure.caption.9}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Estimates on California data}{9}{section.4}}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces Observed and counterfactual predicted outcomes for treated unit in California dataset.\relax }}{9}{figure.caption.10}}
\newlabel{california-plot}{{9}{9}{Observed and counterfactual predicted outcomes for treated unit in California dataset.\relax }{figure.caption.10}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces Time-series of post-period treatment effects in California dataset. See notes to SM-Fig. \ref  {basque-plot-effects}.\relax }}{10}{figure.caption.11}}
\newlabel{california-plot-effects}{{10}{10}{Time-series of post-period treatment effects in California dataset. See notes to SM-Fig. \ref {basque-plot-effects}.\relax }{figure.caption.11}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {11}{\ignorespaces Per-period randomization $p$-values corresponding to treatment effects on treated and control units in California dataset. \relax }}{11}{figure.caption.12}}
\newlabel{california-plot-pvalues}{{11}{11}{Per-period randomization $p$-values corresponding to treatment effects on treated and control units in California dataset. \relax }{figure.caption.12}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Estimates on West Germany data}{12}{section.5}}
\@writefile{lof}{\contentsline {figure}{\numberline {12}{\ignorespaces Observed and counterfactual predicted outcomes for treated unit in West Germany dataset.\relax }}{12}{figure.caption.13}}
\newlabel{germany-plot}{{12}{12}{Observed and counterfactual predicted outcomes for treated unit in West Germany dataset.\relax }{figure.caption.13}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {13}{\ignorespaces Time-series of post-period treatment effects in West Germany dataset. See notes to Fig. SM-\ref  {basque-plot-effects}.\relax }}{13}{figure.caption.14}}
\newlabel{germany-plot-effects}{{13}{13}{Time-series of post-period treatment effects in West Germany dataset. See notes to Fig. SM-\ref {basque-plot-effects}.\relax }{figure.caption.14}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {14}{\ignorespaces Per-period randomization $p$-values corresponding to treatment effects on treated and control units in West Germany dataset. \relax }}{14}{figure.caption.15}}
\newlabel{germany-plot-pvalues}{{14}{14}{Per-period randomization $p$-values corresponding to treatment effects on treated and control units in West Germany dataset. \relax }{figure.caption.15}{}}
\@writefile{toc}{\contentsline {section}{\numberline {6}RNNs training history: Education spending data}{15}{section.6}}
\@writefile{lof}{\contentsline {figure}{\numberline {15}{\ignorespaces Encoder-decoder networks training (solid line) and validation loss (dashed line). \relax }}{15}{figure.caption.16}}
\newlabel{encoder-decoder-loss-capacity-west}{{15}{15}{Encoder-decoder networks training (solid line) and validation loss (dashed line). \relax }{figure.caption.16}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {16}{\ignorespaces LSTM training (solid line) and validation loss (dashed line). \relax }}{15}{figure.caption.17}}
\newlabel{lstm-loss-capacity-west}{{16}{15}{LSTM training (solid line) and validation loss (dashed line). \relax }{figure.caption.17}{}}
\@writefile{toc}{\contentsline {section}{\numberline {7}Estimates on education spending data}{15}{section.7}}
\@writefile{lof}{\contentsline {figure}{\numberline {17}{\ignorespaces Observed (solid line) and counterfactual predicted (dashed line) outcomes for treated unit. Dashed vertical line represents intervention year. \relax }}{16}{figure.caption.18}}
\newlabel{state-capacity-plot}{{17}{16}{Observed (solid line) and counterfactual predicted (dashed line) outcomes for treated unit. Dashed vertical line represents intervention year. \relax }{figure.caption.18}{}}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Encoder-decoder FPR and MSPE on state capacity placebo tests.\relax }}{16}{table.caption.20}}
\newlabel{encoder-decoder-mpse}{{1}{16}{Encoder-decoder FPR and MSPE on state capacity placebo tests.\relax }{table.caption.20}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {18}{\ignorespaces Time-series of post-period treatment effects in state capacity datasets. Darker line represents the effect on the actual treated unit and each lighter line represents the effects on placebo treated units. Shaded regions represent 95\% randomization confidence intervals. \relax }}{17}{figure.caption.19}}
\newlabel{state-capacity-plot-effects}{{18}{17}{Time-series of post-period treatment effects in state capacity datasets. Darker line represents the effect on the actual treated unit and each lighter line represents the effects on placebo treated units. Shaded regions represent 95\% randomization confidence intervals. \relax }{figure.caption.19}{}}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces LSTM FPR and MSPE on state capacity placebo tests.\relax }}{17}{table.caption.21}}
\newlabel{lstm-mpse}{{2}{17}{LSTM FPR and MSPE on state capacity placebo tests.\relax }{table.caption.21}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {19}{\ignorespaces Encoder-decoder networks: Per-period randomization $p$-values corresponding to treatment effects on treated and control units in state capacity datasets. Darker dot represents $p$-values associated with treatment effects on the actual treated unit and lighter dots represent $p$-values associated with the effects on control units \relax }}{18}{figure.caption.22}}
\newlabel{state-capacity-plot-pvalues}{{19}{18}{Encoder-decoder networks: Per-period randomization $p$-values corresponding to treatment effects on treated and control units in state capacity datasets. Darker dot represents $p$-values associated with treatment effects on the actual treated unit and lighter dots represent $p$-values associated with the effects on control units \relax }{figure.caption.22}{}}
